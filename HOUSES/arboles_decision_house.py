# -*- coding: utf-8 -*-
"""Arboles Decision HOUSE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bvYkGSSsH11jyAOLpSwSHvdm6xw5ExYZ

**Importación de librerías necesarias**
"""

from google.colab import drive
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; 
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn import datasets, metrics
import pydot
from IPython.display import Image
from sklearn import tree
from io import StringIO
from joblib import dump, load

"""**Preproceso**

Montar drive para la carga de datos
"""

drive.mount('/content/drive')

"""Importación de los datos del dataset"""

df = pd.read_csv("/content/drive/MyDrive/housing.csv")

"""Mostrar las primeras y últimas filas del dataframe importado

"""

df

"""Tipos de datos del df"""

df.dtypes

"""Mostrar parámetros estadísticos de los datos (media, desviación típica, cuartiles, etc.)"""

df.describe()

"""Mostrar un mapa de calor que indique la correlación entre vriables"""

sns.set()

# para definir el tamaño de cada dato
plt.figure(figsize=(16, 8))

sns.heatmap(df.corr(),annot = True)

"""Seleccionar las características a tener en cuenta en el estudio"""



"""Separar datos entre datos de entrada y etiquetas (resultados)"""

x_house = df.drop('MEDV',axis = 1)
y_house = df['MEDV']

"""Separar datos entre entrenamiento y prueba (usando un 80% para entrenamiento y 20% para test)"""

x_train,x_test,y_train,y_test = train_test_split(x_house,y_house,
                                                 train_size = 0.8,
                                                 test_size = 0.2
                                                 )

"""---


**AQUI COMIENZA LO DE ARBOLES**

---

**Entrenamiento y predicción**

Elegir, instanciar (eligiendo unos valores concretos, por ejemplo profundidad del árbol 3) y entrenar el modelo
"""

# instanciacion

# a diferencia de los otros, este de regresion
arbol = DecisionTreeRegressor(criterion = 'absolute_error',max_depth=3)

# entrenamiento
arbol.fit(x_train,y_train)

"""Realizar una predicción con los datos de prueba"""

# prediccion
y_predict = arbol.predict(x_test)

y_predict

"""Mostrar el árbol de decisión resultante"""

tree.export_graphviz(arbol)

"""Mostrar la importancia de cada atributo en el árbol resultante"""

from pandas._libs.tslibs import dtypes
dot_data = StringIO()

# regresor no tiene

# arbol_classes = []
# arbol_classes
# for i in arbol.classes_:
#   i = str(i)
#   arbol_classes.append(i)

tree.export_graphviz(arbol, out_file = dot_data, feature_names = x_train.columns,
                     rounded=True, filled = True)

graph = pydot.graph_from_dot_data(dot_data.getvalue())
Image(graph[0].create_png())

"""Intenta guardar el modelo de predicción ya entrenado usando dump (https://scikitlearn.org/stable/modules/model_persistence.html)"""

dump(arbol, 'arbol.joblib')

arbol2 = load('arbol.joblib')

arbol2

"""Evaluación

Mostrar el error cuadrático medio (mean_squared_error)
Mostrar el error absoluto medio (mean_absolute_error)
"""

# evaluacion
from sklearn.metrics import mean_squared_error
mean_squared_error = mean_squared_error(y_predict,y_test)
print(f"error cuadrático medio: {mean_squared_error}")


from sklearn.metrics import mean_absolute_error
mean_absolute_error = mean_absolute_error(y_predict,y_test)
print(f"error absoluto medio: {mean_absolute_error}")

"""Representar gráficamente los valores predichos con los valores reales"""

import numpy as np


xx = np.stack(i for i in range(y_test.shape[0]))
plt.figure(figsize=(18,10))
plt.plot(xx, y_test, c='r', LineWidth = 2, label = 'data')
plt.plot(xx, y_predict, c='g', LineWidth = 2, label = 'prediction')
plt.axis('tight')
plt.legend()
plt.show()

"""**Optimización de hiperparámetros**

Calcula la combinación de parámetros óptima (profundidad de árbol y criterio). Para ello realiza ejecuciones con cada uno de los valores del criterio para los valores de profundidad de árbol de 1 a 15.
"""

# instanciacion

criterions = ['squared_error','friedman_mse','absolute_error','poisson']
errores_absoluto = []
min_depths = 0
min_criterion = ""

for criterion in criterions:
  for max_depth in range(1,16):
    arbol = DecisionTreeRegressor(criterion = criterion,max_depth=max_depth)

    # entrenamiento
    arbol.fit(x_train,y_train)

    # prediccion
    y_predict = arbol.predict(x_test)

    from sklearn.metrics import mean_absolute_error
    mean_absolute_error = mean_absolute_error(y_predict,y_test)

    errores_absoluto.append(mean_absolute_error)

    if min(errores_absoluto) == mean_absolute_error:
      min_criterion = criterion
      min_depths = max_depth

    from sklearn.metrics import mean_absolute_error
    print(f"mean_absolute_error: {mean_absolute_error(y_test,y_predict)} con criterion como: {criterion} y con max_depths como: {max_depth}")

print(f"El valor min de error absoluto es:{min(errores_absoluto)}, con k={min_criterion}, y w={min_depths}")

"""Finalmente los parámetros elegidos serán los que den mejor media de esas medidas
anteriormente nombradas
"""

# instanciacion

arbol = DecisionTreeRegressor(criterion = min_criterion,max_depth=min_depths)

# entrenamiento
arbol.fit(x_train,y_train)

# prediccion
y_predict = arbol.predict(x_test)

y_predict

tree.export_graphviz(arbol)

dot_data = StringIO()

tree.export_graphviz(arbol, out_file = dot_data, feature_names = x_train.columns,
                     rounded=True, filled = True)

graph = pydot.graph_from_dot_data(dot_data.getvalue())
Image(graph[0].create_png())

"""Mostrar el error cuadrático medio (mean_squared_error) Mostrar el error absoluto medio (mean_absolute_error)"""

# evaluacion
from sklearn.metrics import mean_squared_error
mean_squared_error = mean_squared_error(y_predict,y_test)
print(f"error cuadrático medio: {mean_squared_error}")


from sklearn.metrics import mean_absolute_error
mean_absolute_error = mean_absolute_error(y_predict,y_test)
print(f"error absoluto medio: {mean_absolute_error}")

"""Representar gráficamente los valores predichos con los valores reales"""

import numpy as np


xx = np.stack(i for i in range(y_test.shape[0]))
plt.figure(figsize=(18,10))
plt.plot(xx, y_test, c='r', LineWidth = 2, label = 'data')
plt.plot(xx, y_predict, c='g', LineWidth = 2, label = 'prediction')
plt.axis('tight')
plt.legend()
plt.show()