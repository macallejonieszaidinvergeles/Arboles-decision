# -*- coding: utf-8 -*-
"""Arboles Decision HEART.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pzrLQ75vtLxMtwI-Ajw0_4yoibcYzuj8

**Importación de librerías necesarias**
"""

from google.colab import drive
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; 
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import BernoulliNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn import datasets, metrics
import pydot
from IPython.display import Image
from sklearn import tree
from io import StringIO
from joblib import dump, load

"""**Preproceso**

Montar drive para la carga de datos
"""

drive.mount('/content/drive')

"""Importación de los datos del dataset"""

df = pd.read_csv("/content/drive/MyDrive/heart.csv")

"""Mostrar las primeras y últimas filas del dataframe importado

"""

df

"""Tipos de datos del df"""

df.dtypes

"""Mostrar parámetros estadísticos de los datos (media, desviación típica, cuartiles, etc.)"""

df.describe()

"""Mostrar un mapa de calor que indique la correlación entre vriables"""

sns.set()

# para definir el tamaño de cada dato
plt.figure(figsize=(16, 8))

sns.heatmap(df.corr(),annot = True)

"""Seleccionar las características a tener en cuenta en el estudio"""

# campos : por ahora sin filtar

# df_filtrado  = pd.DataFrame()
# df_filtrado = df[[]].copy()

# df_filtrado

"""Separar datos entre datos de entrada y etiquetas (resultados)"""

x_heart = df.drop('target',axis = 1)
y_heart = df['target']

"""Separar datos entre entrenamiento y prueba (usando un 80% para entrenamiento y 20% para test),  separacion train y test"""

x_train,x_test,y_train,y_test = train_test_split(x_heart,y_heart,
                                                 test_size = 0.2,
                                                 train_size = 0.8)

"""---


**AQUI COMIENZA LO DE ARBOLES**

---

**Entrenamiento y predicción**

Elegir, instanciar (eligiendo unos valores concretos, por ejemplo profundidad del árbol 3) y entrenar el modelo
"""

# instanciacion
arbol = DecisionTreeClassifier(criterion = 'gini',max_depth=3)

# entrenamiento
arbol.fit(x_train,y_train)

"""Realizar una predicción con los datos de prueba"""

# prediccion
y_predict = arbol.predict(x_test)

"""Mostrar el árbol de decisión resultante"""

tree.export_graphviz(arbol)

"""Mostrar la importancia de cada atributo en el árbol resultante"""

from pandas._libs.tslibs import dtypes
dot_data = StringIO()


arbol_classes = []
# arbol_classes
for i in arbol.classes_:
  i = str(i)
  arbol_classes.append(i)

tree.export_graphviz(arbol, out_file = dot_data, class_names= arbol_classes, feature_names = x_train.columns,
                     rounded=True, filled = True)

graph = pydot.graph_from_dot_data(dot_data.getvalue())
Image(graph[0].create_png())

"""Intenta guardar el modelo de predicción ya entrenado usando dump (https://scikitlearn.org/stable/modules/model_persistence.html)"""

dump(arbol, 'arbol.joblib')

arbol2 = load('arbol.joblib')

arbol2

"""**Evaluación**

Mostrar el porcentaje de elementos correctamente clasificados
"""

accuracy_score(y_test,y_predict)

"""Mostrar la predicción realizada (imprimir la variable con la predicción)"""

y_predict

"""Representar gráficamente la clasificación obtenida (matriz de confusión)"""

y_model = y_predict

cm = confusion_matrix(y_test, y_model, labels= arbol.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels= arbol.classes_)
disp.plot()

plt.show()

"""**Optimización de hiperparámetros**

Calcula la combinación de parámetros óptima (profundidad de árbol y criterio). Para ello
realiza ejecuciones con cada uno de los valores del criterio para los valores de profundidad
de árbol de 1 a 15.
"""

# instanciacion

criterions = ['gini','entropy']
porcentajes = []
max_depths = 0
max_criterion = ""

for criterion in criterions:
  for max_depth in range(1,16):
    arbol = DecisionTreeClassifier(criterion = criterion,max_depth=max_depth)

    # entrenamiento
    arbol.fit(x_train,y_train)

    # prediccion
    y_predict = arbol.predict(x_test)

    accuracy_score(y_test,y_predict)


    porcentajes.append(accuracy_score(y_test,y_predict))

    if max(porcentajes) == accuracy_score(y_test,y_predict):
      max_criterion = criterion
      max_depths = max_depth


    print(f"El porcentaje: {accuracy_score(y_test,y_predict)} con criterion como: {criterion} y con max_depth como: {max_depth}")

print(f"El valor max de porcentaje es:{max(porcentajes)}, con criterion = {max_criterion}, y max_depth={max_depths}")

"""Con ello obtendremos una medida de bondad del modelo (accuracy_score o mean_absolute_error)), como lo ejecutaremos 5 veces, calcularemos la media de esas 5 ejecuciones."""

kf = KFold(n_splits = 5)

# parámetros: modelo, los datos de entrenamiento separados (x, y)
# y el KFold con los splits
# devuelve la media de las ejecuciones
def validacion_cruzada_cl(model, x, y, kf):
  fold_accuracy = []
  for train_fold, test_fold in kf.split(x):
    # obtengo cada partición
    x_train_fold = x.iloc[train_fold]
    y_train_fold = y.iloc[train_fold]
    x_test_fold = x.iloc[test_fold]
    y_test_fold = y.iloc[test_fold]
    # entrenamiento
    model.fit(x_train_fold, y_train_fold)
    # predicción
    y_pred = model.predict(x_test_fold)
    # evaluación del modelo
    acc = accuracy_score(y_test_fold, y_pred)
    fold_accuracy.append(acc)
  media_score = sum(fold_accuracy)/len(fold_accuracy)
  return media_score

kf = KFold(n_splits = 5)
validacion_cruzada_cl(arbol,x_train,y_train,kf)

"""Finalmente los parámetros elegidos serán los que den mejor media de esas medidas anteriormente nombradas"""

# instanciacion

arbol = DecisionTreeClassifier(criterion = max_criterion,max_depth=max_depths)

# entrenamiento
arbol.fit(x_train,y_train)

# prediccion
y_predict = arbol.predict(x_test)

y_predict

tree.export_graphviz(arbol)

dot_data = StringIO()

tree.export_graphviz(arbol, out_file = dot_data, class_names= arbol_classes, feature_names = x_train.columns,
                     rounded=True, filled = True)

graph = pydot.graph_from_dot_data(dot_data.getvalue())
Image(graph[0].create_png())

"""Mostrar el porcentaje de elementos correctamente clasificados"""

accuracy_score(y_test,y_predict)

"""Mostrar la predicción realizada (imprimir la variable con la predicción)"""

y_predict

"""Representar gráficamente la clasificación obtenida (matriz de confusión)"""

y_model = y_predict

cm = confusion_matrix(y_test, y_model, labels= arbol.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels= arbol.classes_)
disp.plot()

plt.show()